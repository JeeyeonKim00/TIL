{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOpF9jSigDtjo0sF8w8n6yD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# English Text Preprocessing"],"metadata":{"id":"2KEzQ56jlynJ"}},{"cell_type":"markdown","source":["## Stemming (어간 추출과정)\n","- `Stem`: 어간. 단어를 구성하는 기본 단위\n","  - 'lovely'의 어간 : 'love'\n","  - 'Beautiful'의 어간: 'Beauty'\n","\n","영어는 현재 진행형(`~ing`), 복수(`~s`,`es`),과거형(`ed`)"],"metadata":{"id":"OMGFzGoxl3Mx"}},{"cell_type":"code","source":["# nltk: 영어를 처리할 수 있는 패키지\n","from nltk.stem import LancasterStemmer\n","\n","stemmer = LancasterStemmer()"],"metadata":{"id":"KndpzxMemQoT","executionInfo":{"status":"ok","timestamp":1682603125924,"user_tz":-540,"elapsed":2119,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["samples = ['working','works','worked']\n","\n","for sample in samples:\n","  sample_stem = stemmer.stem(sample)\n","  print(sample,'의 어간 ==>', sample_stem)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_LBOX6RHmeCK","executionInfo":{"status":"ok","timestamp":1682603125925,"user_tz":-540,"elapsed":8,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}},"outputId":"2cde2bd1-fac7-4866-8526-f76abd465d17"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["working 의 어간 ==> work\n","works 의 어간 ==> work\n","worked 의 어간 ==> work\n"]}]},{"cell_type":"markdown","source":["## Lemmatization\n","- 원형 찾기\n","  `is`,`are` 의 원형 -> `be`"],"metadata":{"id":"2hyr57TnmzdG"}},{"cell_type":"code","source":["import nltk\n","\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cpNIryVTnMTT","executionInfo":{"status":"ok","timestamp":1682603126521,"user_tz":-540,"elapsed":599,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}},"outputId":"b04e1c22-c0f2-448e-8571-11168e9d2e8b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["from nltk.stem.wordnet import WordNetLemmatizer\n","\n","lemmatizer = WordNetLemmatizer()"],"metadata":{"id":"T4x-hRfTnli6","executionInfo":{"status":"ok","timestamp":1682603126521,"user_tz":-540,"elapsed":4,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["print( lemmatizer.lemmatize(\"working\", \"v\"), lemmatizer.lemmatize(\"works\", \"v\"), lemmatizer.lemmatize(\"worked\", \"v\") )\n","print( lemmatizer.lemmatize(\"am\", \"v\"), lemmatizer.lemmatize(\"is\", \"v\"), lemmatizer.lemmatize(\"are\", \"v\"))\n","\n","print( lemmatizer.lemmatize(\"dance\", \"n\"), lemmatizer.lemmatize(\"this\", \"n\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kpv8fPpJ38gF","executionInfo":{"status":"ok","timestamp":1682603128093,"user_tz":-540,"elapsed":1576,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}},"outputId":"dde7975f-c7f7-4ca1-8128-0b74c7afc630"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["work work work\n","be be be\n","dance this\n"]}]},{"cell_type":"markdown","source":["# spaCy 활용\n","- 서구권 언어들에 대한 토큰화, 어간 찾기 등을 손쉽게 수행해주는 라이브러리"],"metadata":{"id":"dPRabpp84E5U"}},{"cell_type":"code","source":["import spacy\n","\n","# 언어팩 다운로드\n","nlp = spacy.load('en_core_web_sm')"],"metadata":{"id":"XRMsSr2z41i-","executionInfo":{"status":"ok","timestamp":1682603146769,"user_tz":-540,"elapsed":18680,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["eng_sent = \"I'm at a payphone, trying to call home. All of my change I spent on you. Where have the times gone.. Baby, it's all wrong. Where are the plans we made for two.\""],"metadata":{"id":"sJyH80YP5abD","executionInfo":{"status":"ok","timestamp":1682603146772,"user_tz":-540,"elapsed":72,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# 분석할 문장을 nlp 객체에 넣는다.\n","doc = nlp(eng_sent)\n","doc.text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"b0M5wqr75awe","executionInfo":{"status":"ok","timestamp":1682603314427,"user_tz":-540,"elapsed":684,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}},"outputId":"14742430-909d-4ffe-c4ea-01c0698cc1b8"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"I'm at a payphone, trying to call home. All of my change I spent on you. Where have the times gone.. Baby, it's all wrong. Where are the plans we made for two.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["#  단어 토큰화, 형태소(POS), Lemma 확인\n","for word_token in doc:\n","  print(\"word : {}\\t\\tPOS : {}\\t\\tLemma : {}\".format(word_token.text, word_token.pos_, word_token.lemma_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UhonF_is5y5n","executionInfo":{"status":"ok","timestamp":1682603146774,"user_tz":-540,"elapsed":66,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}},"outputId":"194cc4c3-d441-486a-e956-b2a3c19cd3a1"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["word : I\t\tPOS : PRON\t\tLemma : I\n","word : 'm\t\tPOS : AUX\t\tLemma : be\n","word : at\t\tPOS : ADP\t\tLemma : at\n","word : a\t\tPOS : DET\t\tLemma : a\n","word : payphone\t\tPOS : NOUN\t\tLemma : payphone\n","word : ,\t\tPOS : PUNCT\t\tLemma : ,\n","word : trying\t\tPOS : VERB\t\tLemma : try\n","word : to\t\tPOS : PART\t\tLemma : to\n","word : call\t\tPOS : VERB\t\tLemma : call\n","word : home\t\tPOS : NOUN\t\tLemma : home\n","word : .\t\tPOS : PUNCT\t\tLemma : .\n","word : All\t\tPOS : PRON\t\tLemma : all\n","word : of\t\tPOS : ADP\t\tLemma : of\n","word : my\t\tPOS : PRON\t\tLemma : my\n","word : change\t\tPOS : NOUN\t\tLemma : change\n","word : I\t\tPOS : PRON\t\tLemma : I\n","word : spent\t\tPOS : VERB\t\tLemma : spend\n","word : on\t\tPOS : ADP\t\tLemma : on\n","word : you\t\tPOS : PRON\t\tLemma : you\n","word : .\t\tPOS : PUNCT\t\tLemma : .\n","word : Where\t\tPOS : SCONJ\t\tLemma : where\n","word : have\t\tPOS : AUX\t\tLemma : have\n","word : the\t\tPOS : DET\t\tLemma : the\n","word : times\t\tPOS : NOUN\t\tLemma : time\n","word : gone\t\tPOS : VERB\t\tLemma : go\n","word : ..\t\tPOS : PUNCT\t\tLemma : ..\n","word : Baby\t\tPOS : PROPN\t\tLemma : Baby\n","word : ,\t\tPOS : PUNCT\t\tLemma : ,\n","word : it\t\tPOS : PRON\t\tLemma : it\n","word : 's\t\tPOS : AUX\t\tLemma : be\n","word : all\t\tPOS : ADV\t\tLemma : all\n","word : wrong\t\tPOS : ADJ\t\tLemma : wrong\n","word : .\t\tPOS : PUNCT\t\tLemma : .\n","word : Where\t\tPOS : SCONJ\t\tLemma : where\n","word : are\t\tPOS : AUX\t\tLemma : be\n","word : the\t\tPOS : DET\t\tLemma : the\n","word : plans\t\tPOS : NOUN\t\tLemma : plan\n","word : we\t\tPOS : PRON\t\tLemma : we\n","word : made\t\tPOS : VERB\t\tLemma : make\n","word : for\t\tPOS : ADP\t\tLemma : for\n","word : two\t\tPOS : NUM\t\tLemma : two\n","word : .\t\tPOS : PUNCT\t\tLemma : .\n"]}]},{"cell_type":"code","source":["anti_hero = '''\n","It's me, hi, I'm the problem, it's me.At tea time, everybody agrees\n","\n","'''"],"metadata":{"id":"-VlyMNO95_9u","executionInfo":{"status":"ok","timestamp":1682603146776,"user_tz":-540,"elapsed":60,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["doc1 = nlp(anti_hero)\n"],"metadata":{"id":"Xewjhpvc6ZeA","executionInfo":{"status":"ok","timestamp":1682603146777,"user_tz":-540,"elapsed":60,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["dir(doc1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"93bDf2BL60Oe","executionInfo":{"status":"ok","timestamp":1682603146778,"user_tz":-540,"elapsed":59,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}},"outputId":"3a33be16-72ce-41a8-b4fa-2c95cd1c7928"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['_',\n"," '__bytes__',\n"," '__class__',\n"," '__delattr__',\n"," '__dir__',\n"," '__doc__',\n"," '__eq__',\n"," '__format__',\n"," '__ge__',\n"," '__getattribute__',\n"," '__getitem__',\n"," '__gt__',\n"," '__hash__',\n"," '__init__',\n"," '__init_subclass__',\n"," '__iter__',\n"," '__le__',\n"," '__len__',\n"," '__lt__',\n"," '__ne__',\n"," '__new__',\n"," '__pyx_vtable__',\n"," '__reduce__',\n"," '__reduce_ex__',\n"," '__repr__',\n"," '__setattr__',\n"," '__setstate__',\n"," '__sizeof__',\n"," '__str__',\n"," '__subclasshook__',\n"," '__unicode__',\n"," '_bulk_merge',\n"," '_context',\n"," '_get_array_attrs',\n"," '_realloc',\n"," '_vector',\n"," '_vector_norm',\n"," 'cats',\n"," 'char_span',\n"," 'copy',\n"," 'count_by',\n"," 'doc',\n"," 'ents',\n"," 'extend_tensor',\n"," 'from_array',\n"," 'from_bytes',\n"," 'from_dict',\n"," 'from_disk',\n"," 'from_docs',\n"," 'from_json',\n"," 'get_extension',\n"," 'get_lca_matrix',\n"," 'has_annotation',\n"," 'has_extension',\n"," 'has_unknown_spaces',\n"," 'has_vector',\n"," 'is_nered',\n"," 'is_parsed',\n"," 'is_sentenced',\n"," 'is_tagged',\n"," 'lang',\n"," 'lang_',\n"," 'mem',\n"," 'noun_chunks',\n"," 'noun_chunks_iterator',\n"," 'remove_extension',\n"," 'retokenize',\n"," 'sentiment',\n"," 'sents',\n"," 'set_ents',\n"," 'set_extension',\n"," 'similarity',\n"," 'spans',\n"," 'tensor',\n"," 'text',\n"," 'text_with_ws',\n"," 'to_array',\n"," 'to_bytes',\n"," 'to_dict',\n"," 'to_disk',\n"," 'to_json',\n"," 'to_utf8_array',\n"," 'user_data',\n"," 'user_hooks',\n"," 'user_span_hooks',\n"," 'user_token_hooks',\n"," 'vector',\n"," 'vector_norm',\n"," 'vocab']"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["#  단어 토큰화, 형태소(POS), Lemma 확인\n","for word_token in doc1:\n","  print(\"word : {}\\t\\tPOS : {}\\t\\tLemma : {}\".format(word_token.text, word_token.pos_, word_token.lemma_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aQhjKQsa6dvm","executionInfo":{"status":"ok","timestamp":1682603146779,"user_tz":-540,"elapsed":53,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}},"outputId":"874d9be1-6820-4433-9267-f1179fd3fee2"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["word : \n","\t\tPOS : SPACE\t\tLemma : \n","\n","word : It\t\tPOS : PRON\t\tLemma : it\n","word : 's\t\tPOS : AUX\t\tLemma : be\n","word : me\t\tPOS : PRON\t\tLemma : I\n","word : ,\t\tPOS : PUNCT\t\tLemma : ,\n","word : hi\t\tPOS : INTJ\t\tLemma : hi\n","word : ,\t\tPOS : PUNCT\t\tLemma : ,\n","word : I\t\tPOS : PRON\t\tLemma : I\n","word : 'm\t\tPOS : AUX\t\tLemma : be\n","word : the\t\tPOS : DET\t\tLemma : the\n","word : problem\t\tPOS : NOUN\t\tLemma : problem\n","word : ,\t\tPOS : PUNCT\t\tLemma : ,\n","word : it\t\tPOS : PRON\t\tLemma : it\n","word : 's\t\tPOS : AUX\t\tLemma : be\n","word : me\t\tPOS : PRON\t\tLemma : I\n","word : .\t\tPOS : PUNCT\t\tLemma : .\n","word : At\t\tPOS : ADP\t\tLemma : at\n","word : tea\t\tPOS : NOUN\t\tLemma : tea\n","word : time\t\tPOS : NOUN\t\tLemma : time\n","word : ,\t\tPOS : PUNCT\t\tLemma : ,\n","word : everybody\t\tPOS : PRON\t\tLemma : everybody\n","word : agrees\t\tPOS : VERB\t\tLemma : agree\n","word : \n","\n","\t\tPOS : SPACE\t\tLemma : \n","\n","\n"]}]},{"cell_type":"markdown","source":["# 한국어 텍스트 정제"],"metadata":{"id":"FfLiFyVr7P6N"}},{"cell_type":"code","source":["korean_text_sample=\"\"\"\n","                    \n","                        1주째는 양호했는데 이번에받은건 스티로폼박스깨져서 일회성비닐팩으로 덧붙여서 보내왔네요\n","                        \n","                        \n","샐러드팩도 뜯어져있고..\n","\n","먹어도되나싶을정도 실망스럽습니다.\n","                    \n","                \"\"\""],"metadata":{"id":"cMgPdMTw7SVa","executionInfo":{"status":"ok","timestamp":1682603146780,"user_tz":-540,"elapsed":46,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# 정규식을 이용해 정제\n","import re\n","\n","korean_text_re = re.sub('\\n','',korean_text_sample)\n","korean_text_re = korean_text_re.strip()\n","\n","# # 공백 문자가 2번 이상 반복되면 공백 하나로 치환\n","korean_text_re = re.sub('\\s{2,}',' ',korean_text_sample)\n","\n","print(korean_text_re)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5AcagKOG7UQN","executionInfo":{"status":"ok","timestamp":1682603918855,"user_tz":-540,"elapsed":14,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}},"outputId":"a840f4fa-efcb-4dde-abd8-e2f6d09e521a"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":[" 1주째는 양호했는데 이번에받은건 스티로폼박스깨져서 일회성비닐팩으로 덧붙여서 보내왔네요 샐러드팩도 뜯어져있고.. 먹어도되나싶을정도 실망스럽습니다. \n"]}]},{"cell_type":"markdown","source":["## 맞춤법 정리 : 보류✂️\n","- py-hanspell: 딥러닝 기반으로 한국어 맞춤법 및 띄어쓰기를 정리리"],"metadata":{"id":"5buIa_kn8fUF"}},{"cell_type":"code","source":["!pip install git+https://github.com/ssut/py-hanspell.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yBlYfKdO7dJE","executionInfo":{"status":"ok","timestamp":1682603154024,"user_tz":-540,"elapsed":7283,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}},"outputId":"15927544-c5c2-47b4-9598-ae8ec6db9213"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/ssut/py-hanspell.git\n","  Cloning https://github.com/ssut/py-hanspell.git to /tmp/pip-req-build-674p7dak\n","  Running command git clone --filter=blob:none --quiet https://github.com/ssut/py-hanspell.git /tmp/pip-req-build-674p7dak\n","  Resolved https://github.com/ssut/py-hanspell.git to commit 8e993cf46f97f9d665c15633a0fc78ac1b727713\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from py-hanspell==1.1) (2.27.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->py-hanspell==1.1) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->py-hanspell==1.1) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->py-hanspell==1.1) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->py-hanspell==1.1) (2.0.12)\n","Building wheels for collected packages: py-hanspell\n","  Building wheel for py-hanspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-hanspell: filename=py_hanspell-1.1-py3-none-any.whl size=4865 sha256=f38aa77983422aac77aaf213bc26c7518787fa03c6e7bfc577b1fa24492ef552\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-k41blxqz/wheels/94/bc/ef/2cb90c305d609f8086489e7e1bd69f21e955118f26938609b7\n","Successfully built py-hanspell\n","Installing collected packages: py-hanspell\n","Successfully installed py-hanspell-1.1\n"]}]},{"cell_type":"code","source":["from hanspell import spell_checker\n","!pip install --upgrade hanspell\n","\n","# 맞춤법 검사 테스트\n","text ='맞춤뻡. 틀리면 외 않되?'\n","\n","# hanspell_text = spell_checker.check(text).checked\n","hanspell_text = spell_checker.check(text).checked"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":416},"id":"xF8wDXlk8pm8","executionInfo":{"status":"error","timestamp":1682603158609,"user_tz":-540,"elapsed":3366,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}},"outputId":"bdfef36c-9f22-4836-e1f8-a79f379b8490"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement hanspell (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for hanspell\u001b[0m\u001b[31m\n","\u001b[0m"]},{"output_type":"error","ename":"JSONDecodeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-ab70599c36eb>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# hanspell_text = spell_checker.check(text).checked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mhanspell_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspell_checker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/hanspell/spell_checker.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'result'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'html'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     result = {\n","\u001b[0;32m/usr/lib/python3.9/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.9/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.9/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"]}]},{"cell_type":"markdown","source":["## 띄어쓰기 관리 패키지 - PyKoSpacing"],"metadata":{"id":"eK8JAYeh-PqI"}},{"cell_type":"code","source":["!pip install git+https://github.com/haven-jeon/PyKoSpacing.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ki7PEESh_tTF","executionInfo":{"status":"ok","timestamp":1682604243715,"user_tz":-540,"elapsed":98578,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}},"outputId":"c4b9cf45-9c02-4fec-a0b2-0922f9aa702c"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/haven-jeon/PyKoSpacing.git\n","  Cloning https://github.com/haven-jeon/PyKoSpacing.git to /tmp/pip-req-build-5hpqjeak\n","  Running command git clone --filter=blob:none --quiet https://github.com/haven-jeon/PyKoSpacing.git /tmp/pip-req-build-5hpqjeak\n","  Resolved https://github.com/haven-jeon/PyKoSpacing.git to commit a058e90c9de41889c63bf2ee454bf1de064d70ff\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tensorflow==2.9.3\n","  Downloading tensorflow-2.9.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h5py==3.1.0\n","  Downloading h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl (4.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting argparse>=1.4.0\n","  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n","Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.9/dist-packages (from h5py==3.1.0->pykospacing==0.5) (1.22.4)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.3->pykospacing==0.5) (0.4.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.3->pykospacing==0.5) (1.16.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.3->pykospacing==0.5) (1.14.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.3->pykospacing==0.5) (2.3.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.3->pykospacing==0.5) (0.2.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.3->pykospacing==0.5) (1.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.3->pykospacing==0.5) (67.7.2)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.3->pykospacing==0.5) (16.0.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.3->pykospacing==0.5) (0.32.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.3->pykospacing==0.5) (3.3.0)\n","Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n","  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.3->pykospacing==0.5) (1.54.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.3->pykospacing==0.5) (1.6.3)\n","Collecting protobuf<3.20,>=3.9.2\n","  Downloading protobuf-3.19.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting flatbuffers<2,>=1.12\n","  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n","Collecting keras<2.10.0,>=2.9.0rc0\n","  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras-preprocessing>=1.1.1\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.3->pykospacing==0.5) (4.5.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.3->pykospacing==0.5) (23.1)\n","Collecting tensorboard<2.10,>=2.9\n","  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.3->pykospacing==0.5) (0.40.0)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.3->pykospacing==0.5) (2.27.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.3->pykospacing==0.5) (2.17.3)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.3->pykospacing==0.5) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.3->pykospacing==0.5) (2.2.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.3->pykospacing==0.5) (3.4.3)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.3->pykospacing==0.5) (4.9)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.3->pykospacing==0.5) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.3->pykospacing==0.5) (0.3.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.3->pykospacing==0.5) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.3->pykospacing==0.5) (6.6.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.3->pykospacing==0.5) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.3->pykospacing==0.5) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.3->pykospacing==0.5) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.3->pykospacing==0.5) (2.0.12)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow==2.9.3->pykospacing==0.5) (2.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.3->pykospacing==0.5) (3.15.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.3->pykospacing==0.5) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.3->pykospacing==0.5) (3.2.2)\n","Building wheels for collected packages: pykospacing\n","  Building wheel for pykospacing (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pykospacing: filename=pykospacing-0.5-py3-none-any.whl size=2268714 sha256=6ab5936340cf106a014e0a83cad273599eddf3ea77056e294206a75b70d628d5\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-kjffkadw/wheels/ca/f2/8d/94e29f54f44b61ffe18da21ed0199d43042bd1350f44107517\n","Successfully built pykospacing\n","Installing collected packages: keras, flatbuffers, argparse, tensorflow-estimator, tensorboard-data-server, protobuf, keras-preprocessing, h5py, google-auth-oauthlib, tensorboard, tensorflow, pykospacing\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.12.0\n","    Uninstalling keras-2.12.0:\n","      Successfully uninstalled keras-2.12.0\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 23.3.3\n","    Uninstalling flatbuffers-23.3.3:\n","      Successfully uninstalled flatbuffers-23.3.3\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.12.0\n","    Uninstalling tensorflow-estimator-2.12.0:\n","      Successfully uninstalled tensorflow-estimator-2.12.0\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.7.0\n","    Uninstalling tensorboard-data-server-0.7.0:\n","      Successfully uninstalled tensorboard-data-server-0.7.0\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.8.0\n","    Uninstalling h5py-3.8.0:\n","      Successfully uninstalled h5py-3.8.0\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.0.0\n","    Uninstalling google-auth-oauthlib-1.0.0:\n","      Successfully uninstalled google-auth-oauthlib-1.0.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.12.2\n","    Uninstalling tensorboard-2.12.2:\n","      Successfully uninstalled tensorboard-2.12.2\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.12.0\n","    Uninstalling tensorflow-2.12.0:\n","      Successfully uninstalled tensorflow-2.12.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed argparse-1.4.0 flatbuffers-1.12 google-auth-oauthlib-0.4.6 h5py-3.1.0 keras-2.9.0 keras-preprocessing-1.1.2 protobuf-3.19.6 pykospacing-0.5 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorflow-2.9.3 tensorflow-estimator-2.9.0\n"]}]},{"cell_type":"code","source":["!pip install --upgrade tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mJLGK5QQBVHw","executionInfo":{"status":"ok","timestamp":1682604318593,"user_tz":-540,"elapsed":64463,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}},"outputId":"cc3c6547-a879-4982-b762-dd9bac9d3620"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (2.9.3)\n","Collecting tensorflow\n","  Downloading tensorflow-2.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras<2.13,>=2.12.0\n","  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.3.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.2.0)\n","Collecting tensorboard<2.13,>=2.12\n","  Downloading tensorboard-2.12.2-py3-none-any.whl (5.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (4.5.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.22.4)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.14.1)\n","Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n","  Downloading protobuf-4.22.3-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0\n","  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.54.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (16.0.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.32.0)\n","Collecting flatbuffers>=2.0\n","  Downloading flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.8)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n","Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n","Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n","Collecting google-auth-oauthlib<1.1,>=0.5\n","  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.2.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n","Collecting tensorboard-data-server<0.8.0,>=0.7.0\n","  Downloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (6.6.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (3.15.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n","Installing collected packages: flatbuffers, tensorflow-estimator, tensorboard-data-server, protobuf, keras, google-auth-oauthlib, tensorboard, tensorflow\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 1.12\n","    Uninstalling flatbuffers-1.12:\n","      Successfully uninstalled flatbuffers-1.12\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.9.0\n","    Uninstalling tensorflow-estimator-2.9.0:\n","      Successfully uninstalled tensorflow-estimator-2.9.0\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.6.1\n","    Uninstalling tensorboard-data-server-0.6.1:\n","      Successfully uninstalled tensorboard-data-server-0.6.1\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.19.6\n","    Uninstalling protobuf-3.19.6:\n","      Successfully uninstalled protobuf-3.19.6\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.9.0\n","    Uninstalling keras-2.9.0:\n","      Successfully uninstalled keras-2.9.0\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 0.4.6\n","    Uninstalling google-auth-oauthlib-0.4.6:\n","      Successfully uninstalled google-auth-oauthlib-0.4.6\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.9.1\n","    Uninstalling tensorboard-2.9.1:\n","      Successfully uninstalled tensorboard-2.9.1\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.9.3\n","    Uninstalling tensorflow-2.9.3:\n","      Successfully uninstalled tensorflow-2.9.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pykospacing 0.5 requires tensorflow==2.9.3, but you have tensorflow 2.12.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed flatbuffers-23.3.3 google-auth-oauthlib-1.0.0 keras-2.12.0 protobuf-4.22.3 tensorboard-2.12.2 tensorboard-data-server-0.7.0 tensorflow-2.12.0 tensorflow-estimator-2.12.0\n"]}]},{"cell_type":"code","source":["from pykospacing import Spacing\n","\n","\n","text = \"아버지가방에들어가신다\"\n","\n","spacing = Spacing()\n","spacing_text = spacing(text)\n","print(spacing_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZshGU_j6_t0J","executionInfo":{"status":"ok","timestamp":1682604320878,"user_tz":-540,"elapsed":2288,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}},"outputId":"1ffcaebe-f58f-491a-a12a-da02fa84a110"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["아버지가 방에 들어가신다\n"]}]},{"cell_type":"code","source":["korean_text_spacing = spacing(korean_text_re)\n","print(korean_text_spacing)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H2AGzhmVC1Iq","executionInfo":{"status":"ok","timestamp":1682604366865,"user_tz":-540,"elapsed":1326,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}},"outputId":"bb56f8c2-0944-4e38-994e-fa3b6bf6c281"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["1주째는 양호했는데 이번에 받은 건 스티로폼 박스 깨져서 일회성 비닐팩으로 덧붙여서 보내왔네요 샐러드팩도 뜯어져 있고.. 먹어도 되나 싶을 정도 실망스럽습니다.\n"]}]},{"cell_type":"markdown","source":["# 한국어 어간 추출\n","- Okt 형태소 분석기"],"metadata":{"id":"MacZ2FRrBfLd"}},{"cell_type":"code","source":["!pip install konlpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MgWEJDR8AZGJ","executionInfo":{"status":"ok","timestamp":1682604619906,"user_tz":-540,"elapsed":9107,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}},"outputId":"a78970cb-8906-40a4-c54d-5fe8b242f903"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.9/dist-packages (from konlpy) (1.22.4)\n","Collecting JPype1>=0.7.0\n","  Downloading JPype1-1.4.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.9/dist-packages (from konlpy) (4.9.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from JPype1>=0.7.0->konlpy) (23.1)\n","Installing collected packages: JPype1, konlpy\n","Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"]}]},{"cell_type":"code","source":["from konlpy.tag import Okt\n","\n","okt = Okt()\n"],"metadata":{"id":"Mvt9bxFuBw02","executionInfo":{"status":"ok","timestamp":1682604623322,"user_tz":-540,"elapsed":3418,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["# mophs: 문장을 형태소 단위로 분리 (단어만 나옴)\n","# pos: 형태소 내용까지 같이 나옴 (단어가 어떤 형태소인지까지 나옴)\n","\n","okt.morphs(korean_text_spacing)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0vRb51ihCBvq","executionInfo":{"status":"ok","timestamp":1682604631064,"user_tz":-540,"elapsed":7754,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}},"outputId":"b09aa675-bb6f-43e3-ca6f-a232b241812f"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['1',\n"," '주',\n"," '째',\n"," '는',\n"," '양호',\n"," '했는데',\n"," '이번',\n"," '에',\n"," '받은',\n"," '건',\n"," '스티로폼',\n"," '박스',\n"," '깨져서',\n"," '일',\n"," '회',\n"," '성',\n"," '비닐',\n"," '팩',\n"," '으로',\n"," '덧붙여서',\n"," '보내왔네요',\n"," '샐러드',\n"," '팩',\n"," '도',\n"," '뜯어져',\n"," '있고',\n"," '..',\n"," '먹어도',\n"," '되나',\n"," '싶을',\n"," '정도',\n"," '실망',\n"," '스럽습니다',\n"," '.']"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["okt.pos(korean_text_spacing)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qNAPrFESCk4x","executionInfo":{"status":"ok","timestamp":1682604631066,"user_tz":-540,"elapsed":19,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}},"outputId":"4c87eec1-bf81-4456-a64b-2276d6a92c6f"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('1', 'Number'),\n"," ('주', 'Noun'),\n"," ('째', 'Suffix'),\n"," ('는', 'Josa'),\n"," ('양호', 'Noun'),\n"," ('했는데', 'Verb'),\n"," ('이번', 'Noun'),\n"," ('에', 'Josa'),\n"," ('받은', 'Verb'),\n"," ('건', 'Noun'),\n"," ('스티로폼', 'Noun'),\n"," ('박스', 'Noun'),\n"," ('깨져서', 'Verb'),\n"," ('일', 'Modifier'),\n"," ('회', 'Noun'),\n"," ('성', 'Suffix'),\n"," ('비닐', 'Noun'),\n"," ('팩', 'Noun'),\n"," ('으로', 'Josa'),\n"," ('덧붙여서', 'Verb'),\n"," ('보내왔네요', 'Verb'),\n"," ('샐러드', 'Noun'),\n"," ('팩', 'Noun'),\n"," ('도', 'Josa'),\n"," ('뜯어져', 'Verb'),\n"," ('있고', 'Adjective'),\n"," ('..', 'Punctuation'),\n"," ('먹어도', 'Verb'),\n"," ('되나', 'Verb'),\n"," ('싶을', 'Verb'),\n"," ('정도', 'Noun'),\n"," ('실망', 'Noun'),\n"," ('스럽습니다', 'Adjective'),\n"," ('.', 'Punctuation')]"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["# 어간 추출\n","okt.morphs(korean_text_spacing, stem=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jIaJfx2_C6-i","executionInfo":{"status":"ok","timestamp":1682604632017,"user_tz":-540,"elapsed":960,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}},"outputId":"8e8883c4-d6ef-4e2a-e124-1e2d4141de91"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['1',\n"," '주',\n"," '째',\n"," '는',\n"," '양호',\n"," '하다',\n"," '이번',\n"," '에',\n"," '받다',\n"," '건',\n"," '스티로폼',\n"," '박스',\n"," '깨다',\n"," '일',\n"," '회',\n"," '성',\n"," '비닐',\n"," '팩',\n"," '으로',\n"," '덧붙이다',\n"," '보내오다',\n"," '샐러드',\n"," '팩',\n"," '도',\n"," '뜯다',\n"," '있다',\n"," '..',\n"," '먹다',\n"," '되다',\n"," '싶다',\n"," '정도',\n"," '실망',\n"," '스럽다',\n"," '.']"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["text='오늘 강남역에서 봅시닿ㅎㅎㅎㅎㅎ'\n","okt.pos(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pl-StUR7DmD0","executionInfo":{"status":"ok","timestamp":1682604632019,"user_tz":-540,"elapsed":25,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}},"outputId":"f62623ac-5ad2-443d-f82a-c7b120e09907"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('오늘', 'Noun'),\n"," ('강남역', 'Noun'),\n"," ('에서', 'Josa'),\n"," ('봅시', 'Verb'),\n"," ('닿', 'Verb'),\n"," ('ㅎㅎㅎㅎㅎ', 'KoreanParticle')]"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["# 정규화\n","okt.pos(text, norm=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w7v7pZeBC_d_","executionInfo":{"status":"ok","timestamp":1682604632020,"user_tz":-540,"elapsed":19,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}},"outputId":"04f467ae-2ce8-4496-d6d8-c0077e6cc746"},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('오늘', 'Noun'),\n"," ('강남역', 'Noun'),\n"," ('에서', 'Josa'),\n"," ('봅시다', 'Verb'),\n"," ('ㅎㅎㅎ', 'KoreanParticle')]"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["# 정규화, 어간 추출을 동시에 \n","okt.pos(text, stem=True, norm=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b7USJ6fgDk37","executionInfo":{"status":"ok","timestamp":1682604632021,"user_tz":-540,"elapsed":15,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}},"outputId":"d0775a25-bced-46cb-b402-e6701775b65e"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('오늘', 'Noun'),\n"," ('강남역', 'Noun'),\n"," ('에서', 'Josa'),\n"," ('보다', 'Verb'),\n"," ('ㅎㅎㅎ', 'KoreanParticle')]"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":[],"metadata":{"id":"fYu7CPCbDym2","executionInfo":{"status":"aborted","timestamp":1682603158627,"user_tz":-540,"elapsed":56,"user":{"displayName":"JeeYeon Kim","userId":"05412234573652083907"}}},"execution_count":null,"outputs":[]}]}