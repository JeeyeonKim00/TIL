# model_selection 모듈

- 학습데이터/테스트 데이터 분리 : train_test_split()
- 교차검증 분할, 평가:
    - KFold
    - StratifiedKFold
    - cross_val_score
- 교차검증 + 최적 하이퍼 파라미터 튜닝 한번에
    - GridSearchCV
    

Kfold가 아닌, **학습데이터/ 테스트 분리**

1. train_test_split()
    
    ```python
    **from sklearn.model_selection import train_test_split**
    from sklearn.datasets import load_iris
    from sklearn.tree import DecisionTreeClassifier
    from sklearn.metrics import accuracy_score
    
    iris = load_iris()
    X_train, X_test, y_train, y_test =train_test_split(
            iris.data, iris.target,
            test_size=0.3, random_state= 121)
    
    dt_clf = DecisionTreeClassifier()
    dt_clf.fit(X_train, y_train)
    pred = dt_clf.predict(X_test)
    print('예측정확도:  {:.3f}'.format(accuracy_score(y_test, pred)))
    
    >>결과
    예측정확도:  0.956
    ```
    

**교차검증**

1. **KFold**
    
    ```python
    **from sklearn.model_selection import KFold**
    import numpy as np
    
    n_iter = 0
    
    # 데이터 로드
    iris = load_iris()
    features = iris.data
    label = iris.target
    
    # 분류기
    dt_clf = DecisionTreeClassifier(random_state =156)
    **kfold = KFold(n_splits=5)**
    cv_accuracy=[]
    
    for train_index, test_index in **kfold.split(features)**:
        X_train, X_test= features[train_index], features[test_index]
        y_train, y_test = label[train_index], label[test_index]
        
        dt_clf.fit(X_train, y_train)
        pred = dt_clf.predict(X_test)
        accuracy = round(accuracy_score(y_test, pred),3)
        cv_accuracy.append(accuracy)
        n_iter +=1
        
        print('{0} 정확도:{1}'.format(n_iter, accuracy))
        print('-'*20)
    
    print('최종 정확도: {:.3f}'.format**(np.mean(cv_accuracy)**))
    
    >>>결과
    1 정확도:1.0
    --------------------
    2 정확도:0.967
    --------------------
    3 정확도:0.867
    --------------------
    4 정확도:0.933
    --------------------
    5 정확도:0.733
    --------------------
    **최종 정확도: 0.900**
    ```
    
    - for train_index, test_index in kfold.split(features):의 결과
        
        kfold = KFold(n_splits=5)로 했으니까 총 5번 나눠짐.
        
        ```
        **n_splits=5니까 총 5번의 검증이 진행됨.**
        **# 첫번째 train, test 세트**
        [ 30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47
          48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65
          66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83
          84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101
         102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119
         120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137
         138 139 140 141 142 143 144 145 146 147 148 149] **# train_index**
        [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
         24 25 26 27 28 29] **# test_index**
        
        **# 두번째 train, test 세트**
        [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
          18  19  20  21  22  23  24  25  26  27  28  29  60  61  62  63  64  65
          66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83
          84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101
         102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119
         120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137
         138 139 140 141 142 143 144 145 146 147 148 149]
        [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
         54 55 56 57 58 59]
        
        **# 세번째 train, test 세트**
        [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
          18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
          36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
          54  55  56  57  58  59  90  91  92  93  94  95  96  97  98  99 100 101
         102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119
         120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137
         138 139 140 141 142 143 144 145 146 147 148 149]
        [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83
         84 85 86 87 88 89]
        
        **# 네번째 train, test 세트**
        [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
          18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
          36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
          54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
          72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
         120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137
         138 139 140 141 142 143 144 145 146 147 148 149]
        [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
         108 109 110 111 112 113 114 115 116 117 118 119]
        
        **# 다섯번째 train, test 세트**
        [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
          18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
          36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
          54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
          72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
          90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
         108 109 110 111 112 113 114 115 116 117 118 119]
        [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137
         138 139 140 141 142 143 144 145 146 147 148 149]
        
        ```
        
    
    #나의 생각—아래것이 더 정확한 것이 아닐까…하는..
    
    ```python
    X_train, X_test, y_train, y_test = train_test_split(
            iris_df.drop('target',axis=1),
            iris_df['target'],
            test_size = 0.3,
            random_state = 121)
    
    # KFold 교차검증!!
    
    kfold= KFold(n_splits=5)
    n_iter = 0
    cv_accuracy=[]
    
    dt_clf = DecisionTreeClassifier(random_state=156)
    
    for train,test in kfold.split(X_train):
        X_train_fold , X_valid= X_train.iloc[train],X_train.iloc[test]
        y_train_fold , y_valid = y_train.iloc[train], y_train.iloc[test]
        
        dt_clf.fit(X_train_fold,y_train_fold)
        pred = dt_clf.predict(X_valid)
        
        acc = np.round(accuracy_score(pred, y_valid),4)
        cv_accuracy.append(acc)
        n_iter+=1
        
        print(f'{n_iter}')
        print(f'학습데이터 인덱스:{train}')
        print(f'검증데이터 인덱스:{test}')
        print('-'*100)
        
    print('평가데이터의 평균 검증 정확도: {:.3f}'.format(np.mean(cv_accuracy)))
    ```
    
2. **StratifiedKFold**
    1. 레이블데이터(target, label데이터)의 분포도(클래스의 비율)에 따라 학습/검증 데이터를 나눈 → 데이터 골고루 분포
    
    ```python
    **from sklearn.model_selection import StratifiedKFold**
    import numpy as np
    
    n_iter = 0
    iris = load_iris()
    features = iris.data
    label = iris.target
    
    dt_clf = DecisionTreeClassifier(random_state =156)
    stf_kfold = StratifiedKFold(n_splits=3)
    cv_accuracy=[]
    
    for train_index, test_index in **stf_kfold.split**(features,**label**):
        X_train, X_test= features[train_index], features[test_index]
        y_train, y_test = label[train_index], label[test_index]
        
        dt_clf.fit(X_train, y_train)
        pred = dt_clf.predict(X_test)
        accuracy = round(accuracy_score(y_test, pred),3)
        cv_accuracy.append(accuracy),3
        n_iter +=1
        
        print('{0} 정확도:{1}'.format(n_iter, accuracy))
        print('-'*20)
    
    print('최종 정확도: {:.3f}'.format(np.mean(cv_accuracy)))
    
    >>>결과
    1 정확도:0.98
    --------------------
    2 정확도:0.94
    --------------------
    3 정확도:0.98
    --------------------
    최종 정확도: 0.967
    ```
    

kfold, stratified kfold= 데이터 분할, cross_val_score= 교차검증 + 결과 반환

1. **cross_val_score()**
    1. KFold (or StratifiedKFold)의 과정을 한번에!
    2. 교차검증 & 결과(scoring)까지 반환
    
    ```python
    **from sklearn.model_selection import cross_val_score**
    
    iris_data = load_iris()
    dt_clf = DecisionTreeClassifier(random_state=156)
    
    data = iris.data
    label = iris.target
    
    scores = **cross_val_score(dt_clf, data, label, scoring='accuracy',cv=3)**
    
    print('교차 검증별 정확도:', scores)
    print('평균 검증 정확도:', round(np.mean(scores),4))
    
    >>>결과
    교차 검증별 정확도: [0.98 0.94 0.98]
    평균 검증 정확도: 0.9667
    ```
    

**교차검증 & 최적 파라미터 튜닝 한번에**

1. **GridSearchCV → best_params_, best_score_, best_estimator_**

```python
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
**from sklearn.model_selection import GridSearchCV**

iris_data = load_iris()

X_train, X_test, y_train, y_test = train_test_split(
				iris_data.data, iris_data.target,
			  test_size= 0.2, random_state =121)

dtree = DecisionTreeClassifier()

grid_parameters ={'max_depth':[1,2,3],
									'min_samples_split':[2,3]}

grid_dtree = GridSearchCV(dtree, **param_grid** = grid_parameters, **cv**=3, **refit**=True)
grid_dtree.fit(X_train, y_train)

```

**GridSearchCV의 결과** 

- fit(학습)한 결과가 **cv_results_에 저장됨 (df로 만들어서 보면 편함)**

```python
scores_df = pd.DataFrame(grid_dtree.**cv_results_**)
scores_df[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score','split2_test_score']]

**>>결과**
max_depth:3 & min_samples_split:2 일때 rank 1위임 = 최고 파라미터
```

![Untitled](model_selection%20%E1%84%86%E1%85%A9%E1%84%83%E1%85%B2%E1%86%AF%203673dfc6955f42dfba190266664a2955/Untitled.png)

**GridSearchCV 객체의 fit()을 수행한 결과**

**X_test, y_test를 이용하여 학습한 결과!!!!**

- 최고 성능을 나타낸 하이퍼 파라미터 값은 **best_params_**
- 그때의 평가 결과 값(정확도)은 **best_score_**에 저장됨.

```python

print('GridSearchCV 최적 파라미터:', grid_dtree.**best_params_**)
print('GridSearchCV 최고 정확도:{:.3f}'.format(grid_dtree.**best_score_**) )

>>>결과
GridSearchCV 최적 파라미터: {'max_depth': 3, 'min_samples_split': 2}
GridSearchCV 최고 정확도:0.975 # 훈련데이터에서의 최고 성능(정확도)
```

**parameter 설정 시 refit=True로 설정하면 테스트 결과 중 최고의 파라미터 조합으로 모델을 학습하여 best_estimator_에 저장해줌**

여기서는 max_depth:3, min_samples_split:2일때가 최적이었고, 

이 파라미터를 가지고 dtree를 학습(fit)한 것을 **best_estimator_**에 저장해놓음.

best_estimator_(X_train, y_train결과 최적 파라미터라고 결론지어진 max_depth:3, minn_samples_split:2) 를 가지고 

이제 테스트 데이터인 X_test에 predict()를,

y_test와 pred값을 이용하여 accuracy를 산출함

```python
estimator = grid_dtree.**best_estimator_** # 최적의 파라미터를 가지고 학습한 것을 estimator에 저장해놓음

 
# 최적의 파라미터일 때 예측 결과.
pred = estimator.**predict(**X_test)
print('테스트 데이터의 세트 정확도: {:.4f}'.format(accuracy_score(y_test, pred)))

>>결과
테스트 데이터의 세트 정확도: 0.9667 # 테스트 데이터에 대한 성능
# max_depth:2 & min_samples_split2일 때(=최적의 파라미터,best_params)일때의 정확도
```