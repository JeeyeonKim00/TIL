# Decision Tree

회귀, 분류에 모두 사용 가능

‘정보 균일도’ 라는 룰을 기반으로 하고 있어 알고리즘이 직관적임.

- **정보균일도 측정 지표**
    - 정보이득지수
        - 1-엔트로피 지수(혼잡도, 서로 다른값많으면 엔트로피 높음)
        - 결정트리는 정보이득지수가 높은 속성을 기준으로 분할
        - 정보이득지수↑ 균일도 ↑
    - **지니계수**
        - 불평등지수
        - 0 가장 평등 → 1 불평등
        - 지니계수↓ 데이터 균일도↑
        - 결정트리는 지니계수가 낮은 속성을 기준으로 분할

- **파라미터**
    - **min_samples_split**
    - **max_depth**
    - min_samples_leaf
    - max_features

### 데이터 로드

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

iris_data = load_iris()

X_train, X_test, y_train, y_test = train_test_split(
  iris_data.data,
  iris_data.target,
  test_size=0.2,
  random_state=11
)
```

### 결정트리

```python
**from sklearn.tree import DecisionTreeClassifier**

dt_clf = DecisionTreeClassifier()
dt_clf.fit(X_train,y_train)
```

### 결정트리 시각화 → Graphviz

```python
**from sklearn.tree import export_graphviz**

export_graphviz(
        dt_clf,
        out_file = 'tree11.dot',
        class_names= iris_data.target_names,
        feature_names = iris_data.feature_names,
        impurity= True,
        filled= True)
```

```python
**import graphviz**

with open('tree11.dot') as f:
    dot_graph = f.read()

graphviz.Source(dot_graph)
```

![Untitled](Decision%20Tree%208a716c93e4fd47b9bd994c97fdde49ec/Untitled.png)

### 트리 정확도 확인

```python
**from sklearn.metrics import accuracy_score**

train_pred = dt_clf.predict(X_train)
test_pred = dt_clf.predict(X_test)

print('훈련 세트에 대한 점수: {:.3f}'.format(accuracy_score(y_train, train_pred)))
print('테스트 세트에 대한 점수: {:.3f}'.format(accuracy_score(y_test, test_pred)))

>>결과:

훈련 세트에 대한 점수: 1.000   
**#----> 과적합!!!!! max_depth통해 과적합 해결
# fit을 X_train, y_train으로 했는데,,, 당연한거 아닐까..?**
테스트 세트에 대한 점수: 0.933

```

### max_depth 이용한 질문의 깊이 제어 (과적합 해결)

```python
dt_clf_depth_2 = DecisionTreeClassifier(**max_depth=2**).fit(X_train,y_train)
```

### 정확도 다시 확인

```python
train_pred = dt_clf_depth_2.predict(X_train) # 알고 있는 데이터에 대한 예측
test_pred  = dt_clf_depth_2.predict(X_test)  # 새로 보는 데이터에 대한 예측

print("훈련 세트에 대한 점수 : {:.3f}".format(accuracy_score(y_train, train_pred)))
print("테스트 세트에 대한 점수 : {:.3f}".format(accuracy_score(y_test, test_pred)))

>> 결과:
훈련 세트에 대한 점수 : 0.967
테스트 세트에 대한 점수 : 0.867
```

### 각 피처 중요도 확인

```python
dt_clf.feature_importances_
>>>array([0.02500521, 0.        , 0.55490281, 0.42009198])
##    sepal_length  sepal width    petal length  petal width
```

```python
import seaborn as sns
import numpy as np
%matplotlib inline

print("feature importances:\n{0}".format(np.round(dt_clf.feature_importances_,3)))

for name, value, in zip(iris_data.feature_names, dt_clf.feature_importances_):
    print(name, value)
    
sns.barplot(x=dt_clf.feature_importances_, y=iris_data.feature_names)
```

![Untitled](Decision%20Tree%208a716c93e4fd47b9bd994c97fdde49ec/Untitled%201.png)
